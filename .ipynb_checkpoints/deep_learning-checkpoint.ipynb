{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8b48b8d-d2fd-4ed2-a5bb-8bb62a66124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import selectivesearch\n",
    "from detection import build_detection_validation\n",
    "from CNNdetection import Sign_Classifier,detection_images_in_folderï¼ŒTrafficSignDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b3ce5-d5c7-44eb-b7c5-ab487e6c20de",
   "metadata": {},
   "source": [
    "## Negative examples generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a2268-4300-4c9c-a49e-b51c8633d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "images_dir_train = \"C:/Users/23158/Desktop/SY32PROJET/dataset/train/images\"\n",
    "labels_dir_train = \"C:/Users/23158/Desktop/SY32PROJET/dataset/train/labels\"\n",
    "negative_samples_dir = \"C:/Users/23158/Desktop/SY32PROJET/dataset2/train/cropped_images\"\n",
    "\n",
    "# Generate and save negative samples\n",
    "generate_negative_samples(images_dir_train, labels_dir_train, negative_samples_dir, target_sizes=[(200, 200), (400, 400)], num_samples=2)\n",
    "generate_negative_samples(images_dir_train, labels_dir_train, negative_samples_dir, target_sizes=[(128, 128), (64, 64)], num_samples=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2446f2d-9f66-4a73-9901-3f4bd1fa4c5b",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d20619-3eaf-4823-b813-e20a9808a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = TrafficSignDataset(data_dir='C:/Users/23158/Desktop/SY32PROJET/dataset/train/cropped_images', transform=transform)\n",
    "val_dataset = TrafficSignDataset(data_dir='C:/Users/23158/Desktop/SY32PROJET/dataset/val/cropped_images', transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe170e-f00e-4b5f-b091-e49f42d2caa7",
   "metadata": {},
   "source": [
    "## First Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585bc4d8-00ea-444c-bdbc-e11da2c56762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model \n",
    "clf = Sign_Classifier()\n",
    "clf.fit(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8a7c2-4249-4cf6-9ebf-6bbbf11f5f98",
   "metadata": {},
   "source": [
    "## Loadmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73732838-393d-40b0-9b2b-ded0672bd0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadmodel\n",
    "model_path = 'traffic_sign_restnet18_v1.pth' \n",
    "clf = Sign_Classifier()\n",
    "clf.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ac09f-5714-4b03-8306-649d3ecec7bf",
   "metadata": {},
   "source": [
    "## First Detection on val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92a2d8-35e7-4609-afac-975ec8cc7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_images_in_folder('C:/Users/23158/Desktop/SY32PROJET/dataset2/val/images', clf, 'detections.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357027a-4d9b-4972-8915-8891ee01f22b",
   "metadata": {},
   "source": [
    "## Augmentating train none label with the false positive of other labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca78db3-39ae-47d3-9e71-829036e43259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection import build_detection_validation\n",
    "label_path = \"C:/Users/23158/Desktop/SY32PROJET/dataset2/train/labels\"\n",
    "build_detection_validation(label_path)\n",
    "validations = pd.read_csv('validations.csv', header=None)\n",
    "detections = pd.read_csv('detections.csv', header=None)\n",
    "negative_samples_dir = \"C:/Users/23158/Desktop/SY32PROJET/dataset2/train/cropped_images\"\n",
    "image_folder_path = \"C:/Users/23158/Desktop/SY32PROJET/dataset2/train/images\"\n",
    "\n",
    "def iou(box1, box2):\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    \n",
    "    x_left = max(int(box1[0]), int(box2[0]))\n",
    "    y_top = max(int(box1[1]), int(box2[1]))\n",
    "    x_right = min(int(box1[2]), int(box2[2]))\n",
    "    y_bottom = min(int(box1[3]), int(box2[3]))\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The area of intersection\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # The area of both the prediction and ground-truth rectangles\n",
    "    box1_area = (int(box1[2]) - int(box1[0])) * (int(box1[3]) - int(box1[1]))\n",
    "    box2_area = (int(box2[2]) - int(box2[0])) * (int(box2[3]) - int(box2[1]))\n",
    "\n",
    "    # The area of the union\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # Compute the IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def get_negative_prediction(detections, validations, image_folder_path, negative_samples_dir):\n",
    "    if image_folder_path== \"dataset/val/images\" or image_folder_path== \"dataset/test\":\n",
    "        print(\"Cannot generate negative samples for validation or test set\")\n",
    "        return\n",
    "    if not os.path.exists(negative_samples_dir):\n",
    "        os.makedirs(negative_samples_dir)\n",
    "\n",
    "    negative_predictions = []\n",
    "    for _, detection_row in detections.iterrows():\n",
    "        image_id_d, x_min_d, y_min_d, x_max_d, y_max_d, score_d, label_d = detection_row\n",
    "        no_intersection = True\n",
    "\n",
    "        for _, validation_row in validations.iterrows():\n",
    "            image_id_v, x_min_v, y_min_v, x_max_v, y_max_v, label_v = validation_row\n",
    "\n",
    "            if image_id_v == image_id_d:\n",
    "                iou_value = iou((x_min_v, y_min_v, x_max_v, y_max_v), (x_min_d, y_min_d, x_max_d, y_max_d))\n",
    "                if iou_value >= 0.3 or label_v == label_d:\n",
    "                    no_intersection = False\n",
    "                    break\n",
    "\n",
    "        if no_intersection and label_d != 'none':\n",
    "            negative_predictions.append((image_id_d, x_min_d, y_min_d, x_max_d, y_max_d, label_d))\n",
    "\n",
    "    for i, (image_id, x_min, y_min, x_max, y_max, label) in enumerate(negative_predictions):\n",
    "        print(image_id)\n",
    "        image_path = os.path.join(image_folder_path, f\"{image_id}\")\n",
    "        image = Image.open(image_path)\n",
    "        cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "        save_path = os.path.join(negative_samples_dir, f\"negative_sample_none_{i}.png\")\n",
    "        cropped_image.save(save_path)\n",
    "\n",
    "get_negative_prediction(detections, validations,image_folder_path, negative_samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40374322-834a-4b72-9efb-da83f69bf875",
   "metadata": {},
   "source": [
    "## Second model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b37ed-6c4a-44fd-9428-fa8f56e1a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrafficSignDataset(data_dir='C:/Users/23158/Desktop/SY32PROJET/dataset/train/cropped_images', transform=transform)\n",
    "clf = Sign_Classifier()\n",
    "clf.fit(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1ea3e-ff3c-41b9-b6b8-767be2293c9f",
   "metadata": {},
   "source": [
    "## Seccond Detection on val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf750d0e-5ab9-4c94-b59f-b14910ec29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_images_in_folder('C:/Users/23158/Desktop/SY32PROJET/dataset2/val/images', clf, 'detections.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade92a3-47d9-4b5e-97b6-59aa0df5c4e2",
   "metadata": {},
   "source": [
    "## Detection on val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7972c-3ae3-4244-9d06-0fc0b8e5d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_images_in_folder('C:/Users/23158/Desktop/SY32PROJET/dataset2/test', clf, 'detections.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1f365-e5a9-43c9-b6e8-84123314e38d",
   "metadata": {},
   "source": [
    "## Map scores and  confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c54cbb-e68e-4674-adfa-09014969cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###get map scores\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "validations = pd.read_csv('validations.csv',header=None)\n",
    "detections = pd.read_csv('detections.csv',header=None) ### put the results detections.csv we get before\n",
    "\n",
    "# Filter out the 'ff' labels\n",
    "validations = validations[validations.iloc[:, 5] != 'ff']\n",
    "detections = detections[detections.iloc[:, 6] != 'ff']\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists to store y (ground truth) and y_pred (predictions)\n",
    "y = []\n",
    "y_pred = []\n",
    "matching_validation_row=[]\n",
    "fp_data=[]\n",
    "# Define IoU function\n",
    "def iou(box1, box2):\n",
    "    # Unpack the coordinates\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "\n",
    "    # Calculate the intersection coordinates\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "\n",
    "    # Calculate the intersection area\n",
    "    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
    "\n",
    "    # Calculate the areas of each box\n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "\n",
    "    # Calculate the union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Calculate the IoU\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "# Match detections with ground truth\n",
    "for _, detection_row in detections.iterrows():\n",
    "    image_id_d, x_min_d, y_min_d, x_max_d, y_max_d, score_d, label_d = detection_row\n",
    "    max_iou = 0.5\n",
    "    matching_validation = 'none'\n",
    "\n",
    "    for _, validation_row in validations.iterrows():\n",
    "        image_id_v, x_min_v, y_min_v, x_max_v, y_max_v, label_v = validation_row\n",
    "        \n",
    "        if image_id_v == image_id_d and label_v == label_d:\n",
    "            iou_value = iou((x_min_v, y_min_v, x_max_v, y_max_v), (x_min_d, y_min_d, x_max_d, y_max_d))\n",
    "            \n",
    "            if iou_value > max_iou:\n",
    "                max_iou = iou_value\n",
    "                matching_validation = label_v\n",
    "                \n",
    "                matching_validation_row.append(_)\n",
    "    \n",
    "    # Add ground truth and prediction based on maximum IoU\n",
    "    #if matching_validation:\n",
    "    \n",
    "    y_pred.append(label_d)\n",
    "    y.append(matching_validation)\n",
    "    \n",
    "    if matching_validation == 'none':\n",
    "       fp_data.append(list(detection_row))\n",
    "\n",
    "\n",
    "#print(len(detections))\n",
    "#print(len(y_pred))\n",
    "#print(len(matching_validation_row))\n",
    "for _, validation_row in validations.iterrows():\n",
    "    image_id_v, x_min_v, y_min_v, x_max_v, y_max_v, label_v = validation_row\n",
    "    if _  not in matching_validation_row:\n",
    "        y.append(label_v)\n",
    "        y_pred.append('none')\n",
    "     \n",
    "\n",
    "#print(len(y_pred))\n",
    "#print(len(y))\n",
    "unique_labels = np.unique(np.concatenate((y, y_pred)))\n",
    "print(\"Unique labels:\", unique_labels)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# plot confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "# Get unique labels\n",
    "unique_labels = sorted(list(set(y)))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2%\",\n",
    "    xticklabels=unique_labels,\n",
    "    yticklabels=unique_labels,\n",
    "    cmap=\"Blues\",\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")\n",
    "plt.show()\n",
    "\n",
    "precision = {}\n",
    "recall = {}\n",
    "\n",
    "for i in range(len(unique_labels)):\n",
    "    cls = unique_labels[i]\n",
    "    tp = cm[i, i]\n",
    "    fp = np.sum(cm[:, i]) - tp\n",
    "    fn = np.sum(cm[i, :]) - tp\n",
    "    \n",
    "    precision[cls] = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall[cls] = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "\n",
    "print(\"Precision:\\n\", precision)\n",
    "print(\"\\nRecall:\\n\", recall)\n",
    "\n",
    "\n",
    "tp_total = np.sum(np.diag(cm))  \n",
    "fp_total = np.sum(cm) - tp_total  \n",
    "fn_total = np.sum(cm) - tp_total  \n",
    "\n",
    "print(tp_total)\n",
    "print(fp_total)\n",
    "print(fn_total)\n",
    "\n",
    "overall_precision = tp_total / (tp_total + fp_total) if tp_total + fp_total > 0 else 0\n",
    "overall_recall = tp_total / (tp_total + fn_total) if tp_total + fn_total > 0 else 0\n",
    "\n",
    "print(\"\\nprecision:\\n\", overall_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
